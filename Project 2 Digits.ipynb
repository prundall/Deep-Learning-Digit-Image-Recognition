{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "## Philip Rundall and Sam Boghese\n",
    "\n",
    "We built two final models. The first is a Feed Forward Neural Network (FFNN) and the second is a Convolutional Neural Network (CNN). After tuning the paramaters in both, the training and testing accuracy can be seen in the DataFrame Below. \n",
    "\n",
    "The CNN is our best performing model but we also provided our best performing FFNN model. \n",
    "\n",
    "To run the FFNN please load the first set of packages, labeled for the FFNN.\n",
    "To run the CNN please load the second set of packages, labeled for the CNN. \n",
    "\n",
    "The CNN is the final model we are submitting, we wanted to show the results from both models though. \n",
    "\n",
    "### Please note that the packages must be reloaded for the CNN to work. If there is a package or loading function error please restart the notebook and load only the second set of packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Nodes in layers</th>\n",
       "      <th>Activation functions</th>\n",
       "      <th>In sample ACC</th>\n",
       "      <th>Out of sample ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>(50,100)</td>\n",
       "      <td>relu,relu</td>\n",
       "      <td>0.936725</td>\n",
       "      <td>0.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>(50,100,30)</td>\n",
       "      <td>relu,relu,relu</td>\n",
       "      <td>0.948250</td>\n",
       "      <td>0.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>(200,100,80,30)</td>\n",
       "      <td>relu,relu,relu,relu</td>\n",
       "      <td>0.954225</td>\n",
       "      <td>0.9488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>(200,100,80,30, 30)</td>\n",
       "      <td>relu,relu,relu,relu, relu</td>\n",
       "      <td>0.957300</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>(100,50,80,30)</td>\n",
       "      <td>relu,relu,relu,relu</td>\n",
       "      <td>0.945725</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>(2D Conv 64 nodes with pooling, 2D Conv 32 nod...</td>\n",
       "      <td>Relu, Relu</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>0.9832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN</td>\n",
       "      <td>(2D Conv 64 nodes with pooling, 2D Conv 32 nod...</td>\n",
       "      <td>Relu, Relu, Relu</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>0.9795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>(2D Conv 64 nodes with pooling, 2D Conv 32 nod...</td>\n",
       "      <td>Relu, Relu, Relu, Relu, Relu</td>\n",
       "      <td>0.986750</td>\n",
       "      <td>0.9748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN</td>\n",
       "      <td>(2D Conv 64 nodes with pooling, 2D Conv 64 nod...</td>\n",
       "      <td>Relu, Relu, Relu</td>\n",
       "      <td>0.994150</td>\n",
       "      <td>0.9822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                    Nodes in layers  \\\n",
       "0  FFNN                                           (50,100)   \n",
       "1  FFNN                                        (50,100,30)   \n",
       "2  FFNN                                    (200,100,80,30)   \n",
       "3  FFNN                                (200,100,80,30, 30)   \n",
       "4  FFNN                                     (100,50,80,30)   \n",
       "5   CNN  (2D Conv 64 nodes with pooling, 2D Conv 32 nod...   \n",
       "6   CNN  (2D Conv 64 nodes with pooling, 2D Conv 32 nod...   \n",
       "7   CNN  (2D Conv 64 nodes with pooling, 2D Conv 32 nod...   \n",
       "8   CNN  (2D Conv 64 nodes with pooling, 2D Conv 64 nod...   \n",
       "\n",
       "           Activation functions  In sample ACC  Out of sample ACC  \n",
       "0                     relu,relu       0.936725             0.9275  \n",
       "1                relu,relu,relu       0.948250             0.9394  \n",
       "2           relu,relu,relu,relu       0.954225             0.9488  \n",
       "3     relu,relu,relu,relu, relu       0.957300             0.9520  \n",
       "4           relu,relu,relu,relu       0.945725             0.9401  \n",
       "5                    Relu, Relu       0.991200             0.9832  \n",
       "6              Relu, Relu, Relu       0.990700             0.9795  \n",
       "7  Relu, Relu, Relu, Relu, Relu       0.986750             0.9748  \n",
       "8              Relu, Relu, Relu       0.994150             0.9822  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(\n",
    "data = [[\"FFNN\",'(50,100)','relu,relu',0.936725,0.9275],\n",
    "[\"FFNN\",'(50,100,30)','relu,relu,relu',0.94825,0.9394],\n",
    "[\"FFNN\",'(200,100,80,30)','relu,relu,relu,relu',0.954225,0.9488],\n",
    "[\"FFNN\",'(200,100,80,30, 30)','relu,relu,relu,relu, relu',0.9573,0.952],\n",
    "[\"FFNN\",'(100,50,80,30)','relu,relu,relu,relu',0.945725,0.9401],\n",
    "[\"CNN\",\"(2D Conv 64 nodes with pooling, 2D Conv 32 nodes with pooling, flatten layer)\",\"Relu, Relu\",0.9912,0.9832],\n",
    "[\"CNN\",\"(2D Conv 64 nodes with pooling, 2D Conv 32 nodes with pooling, flatten layer, 30)\",'Relu, Relu, Relu',0.9907,0.9795],\n",
    "[\"CNN\",\"(2D Conv 64 nodes with pooling, 2D Conv 32 nodes with pooling, flatten layer, 30, 60, 30)\",\"Relu, Relu, Relu, Relu, Relu\",0.98675,0.9748],\n",
    "[\"CNN\",\"(2D Conv 64 nodes with pooling, 2D Conv 64 nodes with pooling, 2D Conv 32 nodes with pooling, flatten layer)\",\"Relu, Relu, Relu\",0.99415,0.9822]],\n",
    "columns = ['Type', 'Nodes in layers','Activation functions','In sample ACC','Out of sample ACC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFNN\n",
    "Our best performing FFNN is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Load these for FFNN\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Conv2D\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import collections \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading training and testing csv's for data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Pixels Training CSV\n",
    "X_train = pd.read_csv('pixels.csv')\n",
    "\n",
    "#Reading the CSV with Training Labels \n",
    "y_train = pd.read_csv('values.csv')\n",
    "\n",
    "#Reading Pixels Testing CSV\n",
    "X_test = pd.read_csv('pixels.csv')\n",
    "\n",
    "#Reading CSV with Testing Labels\n",
    "y_test = pd.read_csv('values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We originally split the training dataset to select our best model but will now use the entire dataset to train the model\n",
    "The code to split the original dataset can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out of sample, splitting training and testing data set with a 0.8 and 0.2 split\n",
    "#Setting random_state so results are replicable\n",
    "#X_train, X_test, y_train, y_test = train_test_split(Xt, Yt, test_size=0.2, random_state=random.randint(1,1000)) \n",
    "# right now i have a random state random state so we dont fit to any specififc subset of split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 1st column of each dataframe\n",
    "X_train = X_train.iloc[:,1:]\n",
    "y_train = y_train.iloc[:,1:]\n",
    "X_test = X_test.iloc[:,1:]\n",
    "y_test = y_test.iloc[:,1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting number of inputs\n",
    "d = X_train.shape[1]\n",
    "\n",
    "#Creating categorical binary variables for keras to use, for both training and testing sets. \n",
    "y_binary_train = keras.utils.to_categorical(y_train)\n",
    "y_binary_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and training model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 4s 88us/sample - loss: 0.7706\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.2250\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1697\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1442\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 78us/sample - loss: 0.1313\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1229\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 81us/sample - loss: 0.1156\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1075\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1073\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 80us/sample - loss: 0.1075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5b4d7dcd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Setting seed of neural network so results are replicable\n",
    "np.random.seed(0)\n",
    "#Instructing to Keras that each line input be a new layer\n",
    "network = models.Sequential()\n",
    "#First hidden layer, 200 units with ReLu activation function. input_shape passes d from above to give size of input layer\n",
    "network.add(layers.Dense(units= 200, activation = \"relu\", input_shape = (d,)))\n",
    "#Second hidden layer, 100 units with ReLu activation function\n",
    "network.add(layers.Dense(units = 100, activation = 'relu'))\n",
    "#Third hidden layer, 80 units with ReLu activation function\n",
    "network.add(layers.Dense(units = 80, activation = 'relu'))\n",
    "#Fourth hidden layer, 30 units with ReLu activation function\n",
    "network.add(layers.Dense(units = 30, activation = 'relu'))\n",
    "#Fifth hidden layer, 30 units with ReLu activation function\n",
    "network.add(layers.Dense(units = 30, activation = 'relu'))\n",
    "#Output Layer, 10 units because there are 10 classifications, activation is softmax\n",
    "network.add(layers.Dense(units = 10, activation = \"softmax\"))\n",
    "#Instructing Keras how to compile the model, using categorical crossentropy for the loss function\n",
    "#Optimizing with rmsprop function\n",
    "network.compile(loss = \"categorical_crossentropy\", optimizer = \"rmsprop\")\n",
    "#Fitting network to training data, 10 epochs with batch size of 100, verbose 1 shows training bars\n",
    "network.fit(X_train, y_binary_train, epochs = 10,verbose = 1, batch_size = 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "#Making predictions with testing data set\n",
    "Y_pred = network.predict(X_test)\n",
    "#Making predictions with training dataset\n",
    "Y_pred_insample = network.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate categorical accuracy\n",
    "# Input the matrices of probability Predictions and actual values. \n",
    "# Matrices should be a sparse nxc where n is the number of \n",
    "# observations and c is the number of classses\n",
    "\n",
    "\n",
    "def categorical_accuracy(preds,y_actual):\n",
    "    # Get the dimensions of the predictions\n",
    "    row = preds.shape[0]\n",
    "    col = preds.shape[1]\n",
    "    #Iterating through each row\n",
    "    for i in range(len(preds)):\n",
    "        #Gets the index of the max value\n",
    "        mx = np.argmax(preds[i])\n",
    "        #Make a vector of all zeros\n",
    "        preds[i] = [0]*col\n",
    "        #replace the max probability with a 1\n",
    "        preds[i][mx] = 1\n",
    "        #Initiate a counter\n",
    "        correct = 0\n",
    "    # make a vector of true and false for correct or not\n",
    "    for i in [y_actual == preds][0]:\n",
    "        if not False in i:\n",
    "            #count true if  true\n",
    "            correct+=1\n",
    "    #return accuracy\n",
    "    return(correct / row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample accuracy: 0.98452 Out of sample accuracy 0.98452\n"
     ]
    }
   ],
   "source": [
    "#Printing categorical accuracy for training and testing datasets with function from above \n",
    "print(\"In sample accuracy:\" ,categorical_accuracy(Y_pred_insample,y_binary_train) ,\"Out of sample accuracy\" , categorical_accuracy(Y_pred,y_binary_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "Our best performing CNN is shown below. This was our best overall performing model. \n",
    "### Please close notebook and reload packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###Start Here for CNN###\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import collections \n",
    "import random\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the Pixels Training CSV\n",
    "X_train = pd.read_csv('pixels.csv')\n",
    "\n",
    "#Reading the CSV with Training Labels \n",
    "y_train = pd.read_csv('values.csv')\n",
    "\n",
    "#Reading Pixels Testing CSV\n",
    "X_test = pd.read_csv('pixels.csv')\n",
    "\n",
    "#Reading CSV with Testing Labels\n",
    "y_test = pd.read_csv('values.csv')\n",
    "\n",
    "#Observations in train data\n",
    "obs1 = X_train.shape[0]\n",
    "#Observations in test data\n",
    "obs2 = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We originally split the training dataset to select our best model but will now use the entire dataset to train the model\n",
    "The code to split the original dataset can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out of sample, splitting training and testing data set with a 0.8 and 0.2 split\n",
    "#Setting random_state so results are replicable\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random.randint(1,1000)) \n",
    "# right now i have a random state random state so we dont fit to any specififc subset of split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 1st column of each dataframe\n",
    "X_train = X_train.iloc[:,1:]\n",
    "y_train = y_train.iloc[:,1:]\n",
    "X_test = X_test.iloc[:,1:]\n",
    "y_test = y_test.iloc[:,1:]\n",
    "\n",
    "#Turning datasets into numpy arrays\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "#Creating categorical binary variables for keras to use, for both training and testing sets. \n",
    "y_binary_train = keras.utils.to_categorical(y_train)\n",
    "y_binary_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping numpy arrays to be obs1x26x26x1\n",
    "#26 is square root of 676\n",
    "X_train = X_train.reshape(obs1,26,26,1)\n",
    "#Reshaping numpy arrays to be obs2x26x26x1\n",
    "#26 is square root of 676\n",
    "X_test = X_test.reshape(obs2,26,26,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and training model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2678 - accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0558 - accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0367 - accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0202 - accuracy: 0.9934\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0178 - accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0145 - accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0126 - accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7faeade57f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convolutional Neural Network\n",
    "#Setting random seed so results are replicable\n",
    "np.random.seed(0)\n",
    "#Instructing to Keras that each line input be a new layer\n",
    "network = models.Sequential()\n",
    "#First convolutional layer, dimensionality of output space = 64, 3x3 convolutional window, relu activation function, observationsx26x26x1 input shape\n",
    "#Pooling \n",
    "network.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(26,26,1)))\n",
    "#Second convolutional layer, dimensionality of output space = 64, 3x3 convolutional window, relu activation function, observationsx26x26x1 input shape\n",
    "network.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(26,26,1)))\n",
    "#Second convolutional layer, dimensionality of output space = 32, 3x3 convolutional window, relu activation function, observationsx26x26x1 input shape\n",
    "network.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "#Flattens output of convolutional layers\n",
    "network.add(Flatten())\n",
    "#Output layer, 10 units for 10 outputs, softmax activation function \n",
    "network.add(Dense(10, activation='softmax'))\n",
    "#Compiling network, categorical crossentropy loss function, adam optimizer, using accuracy to optimize\n",
    "network.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Trainig model with training data, 10 epochs, batch size of 100, verbose 1 shows training bar\n",
    "network.fit(x=X_train, y=y_binary_train, epochs = 10,verbose = 1, batch_size = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate categorical accuracy\n",
    "# Input the matrices of probability Predictions and actual values. \n",
    "# Matrices should be a sparse nxc where n is the number of \n",
    "# observations and c is the number of classses\n",
    "\n",
    "\n",
    "def categorical_accuracy(preds,y_actual):\n",
    "    # Get the dimensions of the predictions\n",
    "    row = preds.shape[0]\n",
    "    col = preds.shape[1]\n",
    "    #Iterating through each row\n",
    "    for i in range(len(preds)):\n",
    "        #Gets the index of the max value\n",
    "        mx = np.argmax(preds[i])\n",
    "        #Make a vector of all zeros\n",
    "        preds[i] = [0]*col\n",
    "        #replace the max probability with a 1\n",
    "        preds[i][mx] = 1\n",
    "        #Initiate a counter\n",
    "        correct = 0\n",
    "    # make a vector of true and false for correct or not\n",
    "    for i in [y_actual == preds][0]:\n",
    "        if not False in i:\n",
    "            #count true if  true\n",
    "            correct+=1\n",
    "    #return accuracy\n",
    "    return(correct / row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions with testing data set\n",
    "Y_pred = network.predict(X_test)\n",
    "#Making predictions with training dataset\n",
    "Y_pred_insample = network.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In sample accuracy: 0.99768 Out of sample accuracy 0.99768\n"
     ]
    }
   ],
   "source": [
    "#Printing categorical accuracy for training and testing datasets with function from above \n",
    "print(\"In sample accuracy:\" ,categorical_accuracy(Y_pred_insample,y_binary_train) ,\"Out of sample accuracy\" , categorical_accuracy(Y_pred,y_binary_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
